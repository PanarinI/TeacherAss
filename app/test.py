import logging
import os
import base64
import json
import streamlit as st
from openai import OpenAI
from dotenv import load_dotenv

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()
API_KEY = os.getenv("API_KEY")
BASE_URL = os.getenv("BASE_URL")
if not API_KEY:
    logger.error("API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
    exit(1)
if not BASE_URL:
    logger.warning("BASE_URL –Ω–µ —É–∫–∞–∑–∞–Ω, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω URL –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)


def encode_image(uploaded_file):
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ base64"""
    try:
        return base64.b64encode(uploaded_file.read()).decode('utf-8')
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}")
        return None


def analyze_content(image_b64: str):
    """–ï–¥–∏–Ω—ã–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{
                "role": "user",
                "content": [
                    {"type": "text", "text": (
                        "–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —É—á–µ–±–Ω–∏–∫–∞. –û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n"
                        "{\n"
                        "  \"subject\": \"–ü—Ä–µ–¥–º–µ—Ç\",\n"
                        "  \"textbook\": \"–£—á–µ–±–Ω–∏–∫\",\n"
                        "  \"topic\": \"–¢–µ–º–∞\",\n"
                        "  \"exercises\": [\"–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–∞–¥–∞–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞\"],\n"
                        "  \"examples\": [\"–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞\"]\n"
                        "}"
                    )},
                    {"type": "image_url", "image_url": {
                        "url": f"data:image/jpeg;base64,{image_b64}",
                        "detail": "high"
                    }}
                ]
            }],
            max_tokens=1500
        )
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return None


def generate_lesson_plan(context: dict):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–ª–∞–Ω–∞ —Å –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É"""
    try:
        prompt = f"""
        –°–û–ó–î–ê–ô –î–ï–¢–ê–õ–¨–ù–´–ô –ü–õ–ê–ù –£–†–û–ö–ê –° –û–ü–û–†–û–ô –ù–ê –ú–ê–¢–ï–†–ò–ê–õ –£–ß–ï–ë–ù–ò–ö–ê.
        –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤–∫–ª—é—á–∏:
        - –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è: {context.get('exercises', [])[:3]}
        - –ü—Ä–∏–º–µ—Ä—ã –∏–∑ —É—á–µ–±–Ω–∏–∫–∞: {context.get('examples', [])[:2]}
        - –ù–æ–º–µ—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü –∏ —Ä–∞–∑–¥–µ–ª–æ–≤
        - –ü–æ—à–∞–≥–æ–≤—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è —É—á–∏—Ç–µ–ª—è

        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
        - –ü—Ä–µ–¥–º–µ—Ç: {context['subject']}
        - –£—á–µ–±–Ω–∏–∫: {context['textbook']}
        - –¢–µ–º–∞: {context['topic']}
        """

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=2000
        )
        return response.choices[0].message.content
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        return None


# --- –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å ---
st.set_page_config(layout="wide")
st.title("üìò –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —É—Ä–æ–∫–æ–≤ —Å –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ —É—á–µ–±–Ω–∏–∫—É")

if "context" not in st.session_state:
    st.session_state.context = {}

# –õ–µ–≤–∞—è –ø–∞–Ω–µ–ª—å
with st.sidebar:
    st.header("–ó–∞–≥—Ä—É–∑–∫–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤")

    uploaded_file = st.file_uploader("–°—Ç—Ä–∞–Ω–∏—Ü–∞ —É—á–µ–±–Ω–∏–∫–∞", type=["jpg", "png", "jpeg"])
    if uploaded_file:
        with st.spinner("–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞..."):
            if image_b64 := encode_image(uploaded_file):
                analysis = analyze_content(image_b64)
                if analysis:
                    st.session_state.context.update(analysis)
                    st.success("–ö–æ–Ω—Ç–µ–Ω—Ç –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!")
                else:
                    st.error("–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")

# –û—Å–Ω–æ–≤–Ω–∞—è –ø–∞–Ω–µ–ª—å
col1, col2 = st.columns([1, 3])

with col1:
    if st.session_state.context:
        st.subheader("–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã:")
        st.json(st.session_state.context)

    if st.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–ª–∞–Ω —É—Ä–æ–∫–∞", disabled=not st.session_state.context):
        with st.spinner("–°–æ–∑–¥–∞–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–ª–∞–Ω..."):
            plan = generate_lesson_plan(st.session_state.context)
            if plan:
                st.session_state.plan = plan
                st.rerun()

with col2:
    if "plan" in st.session_state:
        st.markdown(st.session_state.plan)
        st.download_button(
            "–°–∫–∞—á–∞—Ç—å –ø–ª–∞–Ω",
            data=st.session_state.plan,
            file_name="lesson_plan.md",
            mime="text/markdown"
        )